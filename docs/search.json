[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "List of posts",
    "section": "",
    "text": "PhD progress of Week13 2024\n\n\n\n\n\n\nwork\n\n\n\n\n\n\n\n\n\nMay 3, 2026\n\n\nWANG Genmeng\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 27, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 24, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/W13_PhD progress/index.html",
    "href": "posts/W13_PhD progress/index.html",
    "title": "PhD progress of Week13 2024",
    "section": "",
    "text": "To review together\n\nLSTM of \\(\\dot P\\)\nread the article of U. Fourssell, try to design a similar structur in PAM\n\nthen compare the time and data needed between ‘semi-physical’ NN and FNN\n\npre-treatement of PINN-\\(\\dot P\\)\n\n\n\n\nAt the first time, LSTM has been used for the prediction of \\(\\dot P\\). The main purpose to do experimentation with LSTM is because \\(\\dot P\\) is not time-independant, which means the evolution of \\(\\dot P\\) relies somehow the input of system and current state of PAM system.\nThe data used for training are from Antoine LENOIR, with 6 different trajectories done by a plateform PAM, there are roughly 90 000 points collected with a time interval of 1e-3s. At each point, we have relative information of PAM as \\({\\cal{D}} =\\lbrace\\theta, \\varepsilon, \\dot \\varepsilon, P, \\dot P, u, q, F\\rbrace\\). In this dataset \\({\\cal{D}}\\), data from real world which means data are measured but not calculated with a model are \\(\\theta, P, u\\). From these three variables, we will get an estimation of the rest variables \\(\\varepsilon, \\dot \\varepsilon, \\dot P, q, F\\) in a certain accurancy level.\n\n\n\n\n\nimport scipy.io\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n%matplotlib inline\n%matplotlib widget\nalpha = 2.347\nA = 330\nB1 = 0.69\nB2 = 0.05 \ntheta_0 = 0.3979 #rads\nD0 = 0.01 #m\nL0 = 0.2 #m\nk=1.4\nr=263.8  #J/(kg*K)\nTemp = 293  #K\nepsilon_max = 0.2\nepsilon_min = -0.03\n\nepsilon_0 = 0\n\nN = 1000\nT = 10 #s\n\ndef H (epsilon) :\n    return np.pi * D0**2 / 4 *(3*(1-epsilon)**alpha/np.tan(theta_0)**2 - 1/np.sin(theta_0)**2)\n\ndef L(epsilon):\n    return A*epsilon*(epsilon - B1)/(epsilon + B2)\n\ndef dVde(epsilon):\n    return np.pi * D0**2 * L0 / 4*(- 1/np.sin(theta_0)**2 + (alpha+1)*(1-epsilon)**(alpha)/np.tan(theta_0)**2)\n\ndef V(epsilon):\n    return np.pi*D0**2*L0/4*(1/np.sin(theta_0)**2 -(1-epsilon)**(alpha)/np.tan(theta_0)**2)*(1-epsilon)\n\ndef Phi(theta):\n    return theta - np.arcsin((epsilon_max+epsilon_min)/(epsilon_max - epsilon_min))\n    \ndef Epsilon(phi):\n    return (epsilon_max - epsilon_min)/2 * np.sin(phi) + (epsilon_max+epsilon_min)/2\n\ndef dotEpsilon(phi):\n    return (epsilon_max - epsilon_min) * np.cos(phi) * np.pi / T\n\ndef Force(epsilon,P):\n    return H(epsilon) * P + L(epsilon)\n\ndef dpdt(P,q,epsilon,dot_epsilon):\n    return k * r * Temp / V(epsilon)*(q - P/(r*Temp) * dVde(epsilon) * dot_epsilon)\n\ne = np.linspace(0,0.2,1000)\nPg = np.linspace(0,600000,1000)\ne,Pg = np.meshgrid(e,Pg)\nH_e = H(e)\nL_e = L(e)\n\nF = H_e * Pg + L_e\n\nfile_mapping = {\n    1:\"A1F1.mat\",\n    2:\"A1F2.mat\",\n    3:\"A2F1.mat\",\n    4:\"A2F2.mat\",\n    5:\"A2_5F1.mat\",\n    6:\"A2_5F2.mat\"\n}\nfile_name = file_mapping.get(1)\nif file_name:\n    # load .mat file\n    data_visual = scipy.io.loadmat(rf'C:\\Users\\gwang\\OneDrive - INSA Lyon\\code Python\\PAMs\\DataAntoirL\\Data_SuiviDeTrajectoire\\{file_name}')\nelse:\n    print(\"Invalid file number !\")\n    \n# Raw data\nepsilon = data_visual['epsilon'][0]\ndot_epsilon = data_visual['d_epsilon'][0] # e_t+1 - e_t /dt = dot_e_t+1\nq = data_visual['qm'][0]\nP_capteur = data_visual['p_capteur'][0]\n\nepsilon = epsilon[:-1] # slice the last element in array\ndot_epsilon  = dot_epsilon[1:] #slice the first element in array\ndot_P = (P_capteur[1:] - P_capteur[:-1])*10**3#dt = 1e-3s #bar/s\nP_capteur = P_capteur[:-1] #bar\nq = q[:-1] # Nl/min\nF_model = Force(epsilon, P_capteur*10**5)\ndot_P_estim = dpdt(P=P_capteur*10**5, q=q*2.1542*10**-5, epsilon=epsilon,dot_epsilon=dot_epsilon )*10**-5\n\n# Filtering raw data\nkernel = np.ones(100) / 100\nfiltered_dot_P = np.convolve(dot_P, kernel, mode='same')\nflitered_dot_P_estim = np.convolve(dot_P_estim, kernel, mode='same')\nfiltered_dot_epsilon = np.convolve(dot_epsilon, kernel, mode='same')\n\n\ntraces = {}\ntraces[1] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=dot_P[::10], mode='markers',  marker=dict(\n        size=2,\n        color='blue',\n        opacity=0.8\n    ))\n\ntraces[2] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=dot_P_estim[::10], mode='markers',  marker=dict(\n        size=2,\n        color='orange',\n        opacity=0.8\n    ))\n\ntraces[3] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=(dot_P-dot_P_estim)[::10], mode='markers',  marker=dict(\n        size=2,\n        color='green',\n        opacity=0.8\n    ))\nfig1 = go.Figure()\nfor trace_name, trace in traces.items():\n    fig1.add_trace(trace)\n\nfig1.show()\n\n                                                \n\n\n\ntracesT2 = {}\ntracesT2[1] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=filtered_dot_P[::10], mode='markers',  marker=dict(\n        size=2,\n        color='blue',\n        opacity=0.8\n    ))\n\ntracesT2[2] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=flitered_dot_P_estim[::10], mode='markers',  marker=dict(\n        size=2,\n        color='orange',\n        opacity=0.8\n    ))\n\ntracesT2[3] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=(filtered_dot_P-flitered_dot_P_estim)[::10], mode='markers',  marker=dict(\n        size=2,\n        color='green',\n        opacity=0.8\n    ))\nfig2 = go.Figure()\nfor trace_name, trace in tracesT2.items():\n    fig2.add_trace(trace)\n\nfig2.show()"
  },
  {
    "objectID": "posts/W13_PhD progress/index.html#lstm--dot-p",
    "href": "posts/W13_PhD progress/index.html#lstm--dot-p",
    "title": "PhD progress of Week13 2024",
    "section": "",
    "text": "At the first time, LSTM has been used for the prediction of \\(\\dot P\\). The main purpose to do experimentation with LSTM is because \\(\\dot P\\) is not time-independant, which means the evolution of \\(\\dot P\\) relies somehow the input of system and current state of PAM system.\nThe data used for training are from Antoine LENOIR, with 6 different trajectories done by a plateform PAM, there are roughly 90 000 points collected with a time interval of 1e-3s. At each point, we have relative information of PAM as \\({\\cal{D}} =\\lbrace\\theta, \\varepsilon, \\dot \\varepsilon, P, \\dot P, u, q, F\\rbrace\\). In this dataset \\({\\cal{D}}\\), data from real world which means data are measured but not calculated with a model are \\(\\theta, P, u\\). From these three variables, we will get an estimation of the rest variables \\(\\varepsilon, \\dot \\varepsilon, \\dot P, q, F\\) in a certain accurancy level.\n\n\n\n\n\nimport scipy.io\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n%matplotlib inline\n%matplotlib widget\nalpha = 2.347\nA = 330\nB1 = 0.69\nB2 = 0.05 \ntheta_0 = 0.3979 #rads\nD0 = 0.01 #m\nL0 = 0.2 #m\nk=1.4\nr=263.8  #J/(kg*K)\nTemp = 293  #K\nepsilon_max = 0.2\nepsilon_min = -0.03\n\nepsilon_0 = 0\n\nN = 1000\nT = 10 #s\n\ndef H (epsilon) :\n    return np.pi * D0**2 / 4 *(3*(1-epsilon)**alpha/np.tan(theta_0)**2 - 1/np.sin(theta_0)**2)\n\ndef L(epsilon):\n    return A*epsilon*(epsilon - B1)/(epsilon + B2)\n\ndef dVde(epsilon):\n    return np.pi * D0**2 * L0 / 4*(- 1/np.sin(theta_0)**2 + (alpha+1)*(1-epsilon)**(alpha)/np.tan(theta_0)**2)\n\ndef V(epsilon):\n    return np.pi*D0**2*L0/4*(1/np.sin(theta_0)**2 -(1-epsilon)**(alpha)/np.tan(theta_0)**2)*(1-epsilon)\n\ndef Phi(theta):\n    return theta - np.arcsin((epsilon_max+epsilon_min)/(epsilon_max - epsilon_min))\n    \ndef Epsilon(phi):\n    return (epsilon_max - epsilon_min)/2 * np.sin(phi) + (epsilon_max+epsilon_min)/2\n\ndef dotEpsilon(phi):\n    return (epsilon_max - epsilon_min) * np.cos(phi) * np.pi / T\n\ndef Force(epsilon,P):\n    return H(epsilon) * P + L(epsilon)\n\ndef dpdt(P,q,epsilon,dot_epsilon):\n    return k * r * Temp / V(epsilon)*(q - P/(r*Temp) * dVde(epsilon) * dot_epsilon)\n\ne = np.linspace(0,0.2,1000)\nPg = np.linspace(0,600000,1000)\ne,Pg = np.meshgrid(e,Pg)\nH_e = H(e)\nL_e = L(e)\n\nF = H_e * Pg + L_e\n\nfile_mapping = {\n    1:\"A1F1.mat\",\n    2:\"A1F2.mat\",\n    3:\"A2F1.mat\",\n    4:\"A2F2.mat\",\n    5:\"A2_5F1.mat\",\n    6:\"A2_5F2.mat\"\n}\nfile_name = file_mapping.get(1)\nif file_name:\n    # load .mat file\n    data_visual = scipy.io.loadmat(rf'C:\\Users\\gwang\\OneDrive - INSA Lyon\\code Python\\PAMs\\DataAntoirL\\Data_SuiviDeTrajectoire\\{file_name}')\nelse:\n    print(\"Invalid file number !\")\n    \n# Raw data\nepsilon = data_visual['epsilon'][0]\ndot_epsilon = data_visual['d_epsilon'][0] # e_t+1 - e_t /dt = dot_e_t+1\nq = data_visual['qm'][0]\nP_capteur = data_visual['p_capteur'][0]\n\nepsilon = epsilon[:-1] # slice the last element in array\ndot_epsilon  = dot_epsilon[1:] #slice the first element in array\ndot_P = (P_capteur[1:] - P_capteur[:-1])*10**3#dt = 1e-3s #bar/s\nP_capteur = P_capteur[:-1] #bar\nq = q[:-1] # Nl/min\nF_model = Force(epsilon, P_capteur*10**5)\ndot_P_estim = dpdt(P=P_capteur*10**5, q=q*2.1542*10**-5, epsilon=epsilon,dot_epsilon=dot_epsilon )*10**-5\n\n# Filtering raw data\nkernel = np.ones(100) / 100\nfiltered_dot_P = np.convolve(dot_P, kernel, mode='same')\nflitered_dot_P_estim = np.convolve(dot_P_estim, kernel, mode='same')\nfiltered_dot_epsilon = np.convolve(dot_epsilon, kernel, mode='same')\n\n\ntraces = {}\ntraces[1] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=dot_P[::10], mode='markers',  marker=dict(\n        size=2,\n        color='blue',\n        opacity=0.8\n    ))\n\ntraces[2] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=dot_P_estim[::10], mode='markers',  marker=dict(\n        size=2,\n        color='orange',\n        opacity=0.8\n    ))\n\ntraces[3] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=(dot_P-dot_P_estim)[::10], mode='markers',  marker=dict(\n        size=2,\n        color='green',\n        opacity=0.8\n    ))\nfig1 = go.Figure()\nfor trace_name, trace in traces.items():\n    fig1.add_trace(trace)\n\nfig1.show()\n\n                                                \n\n\n\ntracesT2 = {}\ntracesT2[1] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=filtered_dot_P[::10], mode='markers',  marker=dict(\n        size=2,\n        color='blue',\n        opacity=0.8\n    ))\n\ntracesT2[2] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=flitered_dot_P_estim[::10], mode='markers',  marker=dict(\n        size=2,\n        color='orange',\n        opacity=0.8\n    ))\n\ntracesT2[3] = go.Scatter3d(x=epsilon[::10], y=P_capteur[::10], z=(filtered_dot_P-flitered_dot_P_estim)[::10], mode='markers',  marker=dict(\n        size=2,\n        color='green',\n        opacity=0.8\n    ))\nfig2 = go.Figure()\nfor trace_name, trace in tracesT2.items():\n    fig2.add_trace(trace)\n\nfig2.show()"
  }
]